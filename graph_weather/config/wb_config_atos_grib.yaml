input:
  variables:
    training:
      basedir: /ec/res4/hpcperm/syma/WeatherBench/grib
      summary-stats:
        precomputed: True
        means: /ec/res4/hpcperm/syma/WeatherBench/netcdf/means-1979-2015.nc
        std-devs: /ec/res4/hpcperm/syma/WeatherBench/netcdf/sds-1979-2015.nc
    validation:
      basedir: /ec/res4/hpcperm/syma/WeatherBench/grib
    test:
      basedir: /ec/res4/hpcperm/syma/WeatherBench/grib
    prediction:
      filename: /ec/res4/hpcperm/syma/WeatherBench/netcdf/test/pl_2020.nc
    names:
      - z
      - t
      - q
      - w
      - u
      - v
    levels: null
  constants:
    filename: /ec/res4/hpcperm/syma/WeatherBench/netcdf/constants.nc
    names:
      - lsm  # land-sea mask, [0, 1]
      - z_scal  # surface geopotential scaled to ~[0, 1]

###################
#  OUTPUT BLOCK
###################
output:
  basedir: /ec/res4/scratch/syma/GNN/WeatherBench
  logging:
    log-dir: logs
    log-interval: 25
  checkpoints:
    ckpt-dir: checkpoints
  model:
    save-top-k: 5
    checkpoint-filename: "gnn-wb-weights-{epoch:02d}-{val_wmse:.3f}"

###################
#  MODEL BLOCK
###################
model:
  debug:
    # this will detect and trace back NaNs / Infs etc. but will slow down training
    anomaly-detection: False
  wandb:
    enabled: False
  tensorboard:
    enabled: False
  dataloader:
    num-workers:
      training: 6
      validation: 2
      inference: 4
    batch-size:
      training: 2
      validation: 2
      inference: 1

  # miscellaneous
  precision: 16
  fast-dev-run: False

  # runs only N training batches [N = integer | null]
  # if null then we run through all the batches
  limit-batches:
    training: 250 # null
    validation: 100 # null
    test: 50
    predict: 50

  # parallel strategy [set to null if you're running on a single node, single device]
  # see here for the various options:
  # https://pytorch-lightning.readthedocs.io/en/stable/extensions/strategy.html
  strategy: null # ddp_find_unused_parameters_false

  # number of GPUs per node and number of nodes (for DDP)
  num-gpus: 1
  num-nodes: 1

  # specific GNN model settings
  lead-time: 6
  max-epochs: 1
  learn-rate: 1.e-3
  # latent graph size
  hidden-dim: 64
  # rounds of message passing
  num-blocks: 3
  # length of the "rollout" window (see Keisler's paper)
  rollout: 4
  # Keisler's three training rounds were:
  # Round 1. ~960,000 batches @ ~0.3 seconds per batch (4-step rollout)
  # Round 2. ~90,000 batches @ ~1.0 seconds per batch (8-step rollout)
  # Round 3. ~70,000 batches @ ~1.5 seconds per batch (12-step rollout)
  # Each batch is an N-step rollout, with batch_size=1
